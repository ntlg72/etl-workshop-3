{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab6a22e",
   "metadata": {},
   "source": [
    "# **Happiness Score Prediction -  Machine Learning**\n",
    "\n",
    "-------------------------------------------------------\n",
    "\n",
    "##  **Objective**\n",
    "Train a **regression machine learning model** to predict the **happiness score** using **a  CSV files**  on world happiness data from 2015 to 2019.The workflow includes:\n",
    "\n",
    "- **Extracting features** from raw datasets (ETL process).\n",
    "- **Training a regression model** using a **70-30 data split** (70% training, 30% testing).\n",
    "- **Streaming transformed data** to a consumer.\n",
    "- **Using the trained model** in the consumer to predict happiness scores.\n",
    "- **Storing predictions** with the corresponding features in a database.\n",
    "- **Evaluating performance** using **testing data and predicted values**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Workflow Overview**\n",
    "\n",
    "**Feature Engineering**  \n",
    "   - Normalize `happiness_score` to fit within **[0,10]**.  \n",
    "   - Scale numerical features using **MinMaxScaler** or **StandardScaler**.  \n",
    "\n",
    "**Model Training**  \n",
    "   - Use a **70-30 train-test split** to train the model.  \n",
    "   - Compare different regression models:\n",
    "     - **Linear Regression**\n",
    "     - **Ridge & Lasso Regression**\n",
    "     - **Random Forest Regressor**\n",
    "     - **XGBoost Regressor**\n",
    "   - **Tune hyperparameters** to improve performance.\n",
    "\n",
    " **Data Streaming**  \n",
    "   - Stream **transformed data** to a consumer.\n",
    "   - Retrieve data from the consumer.\n",
    "   - Use the **trained model** to make predictions.\n",
    "\n",
    " **Database Storage**  \n",
    "   - Store **predictions along with input features** in a database.  \n",
    "   - Ensure data **integrity and accessibility** for future analysis.\n",
    "\n",
    "**Model Evaluation**  \n",
    "   - Compute **Mean Squared Error (MSE)** and **R²**.  \n",
    "   - Analyze **residual distributions** for normality.  \n",
    "   - Validate against **real-world happiness scores**.\n",
    "\n",
    "\n",
    "## **Metadata**\n",
    "- **Author:** Natalia López Gallego  \n",
    "- **Python Version:** 3.12.10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fae56311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from xgboost) (2.2.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from scikit-learn) (2.2.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (0.14.4)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from statsmodels) (2.2.5)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from statsmodels) (1.15.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from statsmodels) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "!pip install scikit-learn\n",
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28d72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model selection y preprocesamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Modelos de regresión\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Métricas de evaluación\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "# Statsmodels para modelos estadísticos\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.othermod.betareg as betareg\n",
    "from statsmodels.genmod.generalized_linear_model import GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ff6293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health_x_economy</th>\n",
       "      <th>economy</th>\n",
       "      <th>health</th>\n",
       "      <th>freedom</th>\n",
       "      <th>family</th>\n",
       "      <th>economy_t-1_x_health_t-1</th>\n",
       "      <th>continent</th>\n",
       "      <th>happiness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097017</td>\n",
       "      <td>0.319820</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>0.23414</td>\n",
       "      <td>1.029510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066301</td>\n",
       "      <td>0.382270</td>\n",
       "      <td>0.173440</td>\n",
       "      <td>0.16430</td>\n",
       "      <td>0.110370</td>\n",
       "      <td>0.097017</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072566</td>\n",
       "      <td>0.401477</td>\n",
       "      <td>0.180747</td>\n",
       "      <td>0.10618</td>\n",
       "      <td>0.581543</td>\n",
       "      <td>0.066301</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.084660</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.08500</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>0.072566</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.126350</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.41700</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>0.084660</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   health_x_economy   economy    health  freedom    family  \\\n",
       "0          0.097017  0.319820  0.303350  0.23414  1.029510   \n",
       "1          0.066301  0.382270  0.173440  0.16430  0.110370   \n",
       "2          0.072566  0.401477  0.180747  0.10618  0.581543   \n",
       "3          0.084660  0.332000  0.255000  0.08500  0.537000   \n",
       "4          0.126350  0.350000  0.361000  0.41700  0.517000   \n",
       "\n",
       "   economy_t-1_x_health_t-1 continent  happiness_score  \n",
       "0                  0.000000      Asia            3.575  \n",
       "1                  0.097017      Asia            3.360  \n",
       "2                  0.066301      Asia            3.794  \n",
       "3                  0.072566      Asia            3.632  \n",
       "4                  0.084660      Asia            3.203  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/interim/happiness_data.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3033d115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   health_x_economy   economy    health  freedom    family  \\\n",
      "0          0.097017  0.319820  0.303350  0.23414  1.029510   \n",
      "1          0.066301  0.382270  0.173440  0.16430  0.110370   \n",
      "2          0.072566  0.401477  0.180747  0.10618  0.581543   \n",
      "3          0.084660  0.332000  0.255000  0.08500  0.537000   \n",
      "4          0.126350  0.350000  0.361000  0.41700  0.517000   \n",
      "\n",
      "   economy_t-1_x_health_t-1  happiness_score  continent_Asia  \\\n",
      "0                  0.000000            3.575             1.0   \n",
      "1                  0.097017            3.360             1.0   \n",
      "2                  0.066301            3.794             1.0   \n",
      "3                  0.072566            3.632             1.0   \n",
      "4                  0.084660            3.203             1.0   \n",
      "\n",
      "   continent_Europe  continent_North America  continent_Oceania  \\\n",
      "0               0.0                      0.0                0.0   \n",
      "1               0.0                      0.0                0.0   \n",
      "2               0.0                      0.0                0.0   \n",
      "3               0.0                      0.0                0.0   \n",
      "4               0.0                      0.0                0.0   \n",
      "\n",
      "   continent_South America  continent_Unknown  \n",
      "0                      0.0                0.0  \n",
      "1                      0.0                0.0  \n",
      "2                      0.0                0.0  \n",
      "3                      0.0                0.0  \n",
      "4                      0.0                0.0  \n"
     ]
    }
   ],
   "source": [
    "# Use 'sparse_output=False' instead of 'sparse=False'\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "encoded_continent = encoder.fit_transform(df[[\"continent\"]])\n",
    "\n",
    "# Convert the encoded array to a DataFrame\n",
    "import pandas as pd\n",
    "continent_df = pd.DataFrame(encoded_continent, columns=encoder.get_feature_names_out([\"continent\"]))\n",
    "\n",
    "# Drop the original 'continent' column and join the new one-hot encoded columns\n",
    "df = df.drop(columns=[\"continent\"]).join(continent_df)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e951505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable and feature definition\n",
    "\n",
    "X = df.drop(columns=[\"happiness_score\"])\n",
    "y = df[\"happiness_score\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0363d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfb34071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name: str, y_true: np.ndarray, y_pred: np.ndarray, results: dict) -> None:\n",
    "    \"\"\"\n",
    "    Evaluates a regression model's performance and stores the results.\n",
    "\n",
    "    Parameters:\n",
    "    - name (str): The name of the model.\n",
    "    - y_true (np.ndarray): Array of actual target values.\n",
    "    - y_pred (np.ndarray): Array of predicted target values.\n",
    "    - results (dict): Dictionary to store evaluation metrics.\n",
    "\n",
    "    Returns:\n",
    "    - None: The function updates the results dictionary in-place.\n",
    "    \"\"\"\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)  # Updated function\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    results[name] = {'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "#  Dictionary to store results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d46df20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "evaluate_model(\"LinearRegression\", y_test, y_pred_lr, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25f48a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2️⃣ GLM Gaussian (identidad)\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "glm_gauss = sm.GLM(y_train, X_train_sm, family=sm.families.Gaussian()).fit()\n",
    "y_pred_glm = glm_gauss.predict(X_test_sm)\n",
    "evaluate_model(\"GLM_Gaussian\", y_test, y_pred_glm, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe25cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3️⃣ Ridge Regression\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "evaluate_model(\"Ridge\", y_test, y_pred_ridge, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a86f5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4️⃣ Lasso Regression\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "evaluate_model(\"Lasso\", y_test, y_pred_lasso, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a651e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5️⃣ Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "evaluate_model(\"RandomForest\", y_test, y_pred_rf, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76082ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6️⃣ XGBoost Regressor\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "evaluate_model(\"XGBoost\", y_test, y_pred_xgb, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12c254b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ntlg2\\Documents\\etl-workshop-3\\venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:13: FutureWarning: The logit link alias is deprecated. Use Logit instead. The logit link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 7️⃣ Beta Regression (requires scaling y between (0,1))\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Convert Series to NumPy arrays and reshape before scaling\n",
    "y_train_beta = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_beta = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Fit the Beta Regression model\n",
    "glm_beta = GLM(y_train_beta, X_train_sm, family=sm.families.Binomial(link=sm.families.links.logit()))\n",
    "beta_model = glm_beta.fit()\n",
    "\n",
    "# Make predictions\n",
    "y_pred_beta = beta_model.predict(X_test_sm)\n",
    "\n",
    "# Reverse scaling to get predictions in the original scale\n",
    "y_pred_beta_rescaled = scaler_y.inverse_transform(y_pred_beta.to_numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(\"BetaRegression_scaled\", y_test, y_pred_beta_rescaled, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4407a1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Model Comparison:\n",
      "                           RMSE        R2\n",
      "RandomForest           0.450144  0.830738\n",
      "XGBoost                0.470869  0.814794\n",
      "GLM_Gaussian           0.472672  0.813372\n",
      "LinearRegression       0.472672  0.813372\n",
      "Ridge                  0.475470  0.811157\n",
      "BetaRegression_scaled  0.480273  0.807322\n",
      "Lasso                  0.676568  0.617634\n"
     ]
    }
   ],
   "source": [
    "# 📋 Mostrar resultados\n",
    "results_df = pd.DataFrame(results).T.sort_values(by=\"RMSE\")\n",
    "print(\"📊 Model Comparison:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d98c4ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Cross-Validation Results:\n",
      "                  CV RMSE (mean)  CV RMSE (std)\n",
      "RandomForest            0.594741       0.027343\n",
      "LinearRegression        0.631722       0.019379\n",
      "Ridge                   0.631722       0.019383\n",
      "XGBoost                 0.644110       0.025131\n",
      "Lasso                   0.644536       0.017037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 🔁 Definir la validación cruzada (por ejemplo, KFold con 5 particiones)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 📦 Modelos a evaluar (excepto GLM y Beta)\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.1),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "# 📊 Evaluación de cada modelo con cross-validation\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Pipeline para escalar y ajustar (excepto Random Forest/XGBoost, pero no afecta negativamente)\n",
    "    pipeline = make_pipeline(StandardScaler(), model)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring='neg_root_mean_squared_error')  # Neg RMSE\n",
    "    cv_results[name] = {\n",
    "        \"CV RMSE (mean)\": -np.mean(scores),\n",
    "        \"CV RMSE (std)\": np.std(scores)\n",
    "    }\n",
    "\n",
    "# 📋 Mostrar resultados\n",
    "cv_df = pd.DataFrame(cv_results).T.sort_values(by=\"CV RMSE (mean)\")\n",
    "print(\"🔁 Cross-Validation Results:\")\n",
    "print(cv_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
