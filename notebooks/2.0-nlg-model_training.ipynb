{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab6a22e",
   "metadata": {},
   "source": [
    "# **Happiness Score Prediction -  Machine Learning**\n",
    "\n",
    "-------------------------------------------------------\n",
    "\n",
    "##  **Objective**\n",
    "Train a **regression machine learning model** to predict the **happiness score** using **a  CSV files**  on world happiness data from 2015 to 2019.The workflow includes:\n",
    "\n",
    "- **Extracting features** from raw datasets (ETL process).\n",
    "- **Training a regression model** using a **70-30 data split** (70% training, 30% testing).\n",
    "- **Streaming transformed data** to a consumer.\n",
    "- **Using the trained model** in the consumer to predict happiness scores.\n",
    "- **Storing predictions** with the corresponding features in a database.\n",
    "- **Evaluating performance** using **testing data and predicted values**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Workflow Overview**\n",
    "\n",
    "**Feature Engineering**  \n",
    "   - Normalize `happiness_score` to fit within **[0,10]**.  \n",
    "   - Scale numerical features using **MinMaxScaler** or **StandardScaler**.  \n",
    "\n",
    "**Model Training**  \n",
    "   - Use a **70-30 train-test split** to train the model.  \n",
    "   - Compare different regression models:\n",
    "     - **Linear Regression**\n",
    "     - **Ridge & Lasso Regression**\n",
    "     - **Random Forest Regressor**\n",
    "     - **XGBoost Regressor**\n",
    "   - **Tune hyperparameters** to improve performance.\n",
    "\n",
    " **Data Streaming**  \n",
    "   - Stream **transformed data** to a consumer.\n",
    "   - Retrieve data from the consumer.\n",
    "   - Use the **trained model** to make predictions.\n",
    "\n",
    " **Database Storage**  \n",
    "   - Store **predictions along with input features** in a database.  \n",
    "   - Ensure data **integrity and accessibility** for future analysis.\n",
    "\n",
    "**Model Evaluation**  \n",
    "   - Compute **Mean Squared Error (MSE)** and **R¬≤**.  \n",
    "   - Analyze **residual distributions** for normality.  \n",
    "   - Validate against **real-world happiness scores**.\n",
    "\n",
    "\n",
    "## **Metadata**\n",
    "- **Author:** Natalia L√≥pez Gallego  \n",
    "- **Python Version:** 3.12.10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fae56311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from xgboost) (2.2.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from scikit-learn) (2.2.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (0.14.4)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from statsmodels) (2.2.5)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from statsmodels) (1.15.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from statsmodels) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Requirement already satisfied: catboost in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from catboost) (3.10.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from catboost) (2.2.5)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from catboost) (1.15.3)\n",
      "Requirement already satisfied: plotly in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from catboost) (6.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from matplotlib->catboost) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from matplotlib->catboost) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from plotly->catboost) (1.40.0)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from lightgbm) (2.2.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\ntlg2\\documents\\etl-workshop-3\\venv\\lib\\site-packages (from lightgbm) (1.15.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "!pip install scikit-learn\n",
    "!pip install statsmodels\n",
    "!pip install catboost\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d28d72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model selection y preprocesamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Modelos de regresi√≥n\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "# M√©tricas de evaluaci√≥n\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "# Statsmodels para modelos estad√≠sticos\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.othermod.betareg as betareg\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3ff6293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health_x_economy</th>\n",
       "      <th>freedom</th>\n",
       "      <th>family</th>\n",
       "      <th>health</th>\n",
       "      <th>economy_t-1_x_health_t-1</th>\n",
       "      <th>family_generosity_ratio</th>\n",
       "      <th>continent</th>\n",
       "      <th>happiness_score</th>\n",
       "      <th>trust</th>\n",
       "      <th>economy_health_ratio</th>\n",
       "      <th>health_x_country_economy_mean</th>\n",
       "      <th>economy</th>\n",
       "      <th>family_t-1_x_freedom_t-1</th>\n",
       "      <th>country_economy_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097017</td>\n",
       "      <td>0.23414</td>\n",
       "      <td>1.029510</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.819726</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.575</td>\n",
       "      <td>0.097190</td>\n",
       "      <td>1.054259</td>\n",
       "      <td>0.108330</td>\n",
       "      <td>0.319820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066301</td>\n",
       "      <td>0.16430</td>\n",
       "      <td>0.110370</td>\n",
       "      <td>0.173440</td>\n",
       "      <td>0.097017</td>\n",
       "      <td>0.352969</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.360</td>\n",
       "      <td>0.071120</td>\n",
       "      <td>2.203920</td>\n",
       "      <td>0.061938</td>\n",
       "      <td>0.382270</td>\n",
       "      <td>0.241049</td>\n",
       "      <td>0.357113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072566</td>\n",
       "      <td>0.10618</td>\n",
       "      <td>0.581543</td>\n",
       "      <td>0.180747</td>\n",
       "      <td>0.066301</td>\n",
       "      <td>1.864633</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.794</td>\n",
       "      <td>0.061158</td>\n",
       "      <td>2.221091</td>\n",
       "      <td>0.064547</td>\n",
       "      <td>0.401477</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>0.357113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.084660</td>\n",
       "      <td>0.08500</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.072566</td>\n",
       "      <td>2.811371</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.632</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>1.301910</td>\n",
       "      <td>0.091064</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.357113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.126350</td>\n",
       "      <td>0.41700</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.084660</td>\n",
       "      <td>3.271945</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.203</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.969502</td>\n",
       "      <td>0.128918</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.045645</td>\n",
       "      <td>0.357113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   health_x_economy  freedom    family    health  economy_t-1_x_health_t-1  \\\n",
       "0          0.097017  0.23414  1.029510  0.303350                  0.000000   \n",
       "1          0.066301  0.16430  0.110370  0.173440                  0.097017   \n",
       "2          0.072566  0.10618  0.581543  0.180747                  0.066301   \n",
       "3          0.084660  0.08500  0.537000  0.255000                  0.072566   \n",
       "4          0.126350  0.41700  0.517000  0.361000                  0.084660   \n",
       "\n",
       "   family_generosity_ratio continent  happiness_score     trust  \\\n",
       "0                 2.819726      Asia            3.575  0.097190   \n",
       "1                 0.352969      Asia            3.360  0.071120   \n",
       "2                 1.864633      Asia            3.794  0.061158   \n",
       "3                 2.811371      Asia            3.632  0.036000   \n",
       "4                 3.271945      Asia            3.203  0.025000   \n",
       "\n",
       "   economy_health_ratio  health_x_country_economy_mean   economy  \\\n",
       "0              1.054259                       0.108330  0.319820   \n",
       "1              2.203920                       0.061938  0.382270   \n",
       "2              2.221091                       0.064547  0.401477   \n",
       "3              1.301910                       0.091064  0.332000   \n",
       "4              0.969502                       0.128918  0.350000   \n",
       "\n",
       "   family_t-1_x_freedom_t-1  country_economy_mean  \n",
       "0                  0.000000              0.357113  \n",
       "1                  0.241049              0.357113  \n",
       "2                  0.018134              0.357113  \n",
       "3                  0.061748              0.357113  \n",
       "4                  0.045645              0.357113  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/interim/happiness_data_alternative.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3033d115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   health_x_economy  freedom    family    health  economy_t-1_x_health_t-1  \\\n",
      "0          0.097017  0.23414  1.029510  0.303350                  0.000000   \n",
      "1          0.066301  0.16430  0.110370  0.173440                  0.097017   \n",
      "2          0.072566  0.10618  0.581543  0.180747                  0.066301   \n",
      "3          0.084660  0.08500  0.537000  0.255000                  0.072566   \n",
      "4          0.126350  0.41700  0.517000  0.361000                  0.084660   \n",
      "\n",
      "   family_generosity_ratio  happiness_score     trust  economy_health_ratio  \\\n",
      "0                 2.819726            3.575  0.097190              1.054259   \n",
      "1                 0.352969            3.360  0.071120              2.203920   \n",
      "2                 1.864633            3.794  0.061158              2.221091   \n",
      "3                 2.811371            3.632  0.036000              1.301910   \n",
      "4                 3.271945            3.203  0.025000              0.969502   \n",
      "\n",
      "   health_x_country_economy_mean   economy  family_t-1_x_freedom_t-1  \\\n",
      "0                       0.108330  0.319820                  0.000000   \n",
      "1                       0.061938  0.382270                  0.241049   \n",
      "2                       0.064547  0.401477                  0.018134   \n",
      "3                       0.091064  0.332000                  0.061748   \n",
      "4                       0.128918  0.350000                  0.045645   \n",
      "\n",
      "   country_economy_mean  continent_Asia  continent_Europe  \\\n",
      "0              0.357113             1.0               0.0   \n",
      "1              0.357113             1.0               0.0   \n",
      "2              0.357113             1.0               0.0   \n",
      "3              0.357113             1.0               0.0   \n",
      "4              0.357113             1.0               0.0   \n",
      "\n",
      "   continent_North America  continent_Oceania  continent_South America  \\\n",
      "0                      0.0                0.0                      0.0   \n",
      "1                      0.0                0.0                      0.0   \n",
      "2                      0.0                0.0                      0.0   \n",
      "3                      0.0                0.0                      0.0   \n",
      "4                      0.0                0.0                      0.0   \n",
      "\n",
      "   continent_Unknown  \n",
      "0                0.0  \n",
      "1                0.0  \n",
      "2                0.0  \n",
      "3                0.0  \n",
      "4                0.0  \n"
     ]
    }
   ],
   "source": [
    "# Use 'sparse_output=False' instead of 'sparse=False'\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "encoded_continent = encoder.fit_transform(df[[\"continent\"]])\n",
    "\n",
    "# Convert the encoded array to a DataFrame\n",
    "import pandas as pd\n",
    "continent_df = pd.DataFrame(encoded_continent, columns=encoder.get_feature_names_out([\"continent\"]))\n",
    "\n",
    "# Drop the original 'continent' column and join the new one-hot encoded columns\n",
    "df = df.drop(columns=[\"continent\"]).join(continent_df)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e951505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable and feature definition\n",
    "\n",
    "X = df.drop(columns=[\"happiness_score\"])\n",
    "y = df[\"happiness_score\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0363d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfb34071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name: str, y_true: np.ndarray, y_pred: np.ndarray, results: dict) -> None:\n",
    "    \"\"\"\n",
    "    Evaluates a regression model's performance and stores the results.\n",
    "\n",
    "    Parameters:\n",
    "    - name (str): The name of the model.\n",
    "    - y_true (np.ndarray): Array of actual target values.\n",
    "    - y_pred (np.ndarray): Array of predicted target values.\n",
    "    - results (dict): Dictionary to store evaluation metrics.\n",
    "\n",
    "    Returns:\n",
    "    - None: The function updates the results dictionary in-place.\n",
    "    \"\"\"\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)  # Updated function\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    results[name] = {'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "#  Dictionary to store results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d46df20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "evaluate_model(\"LinearRegression\", y_test, y_pred_lr, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25f48a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ GLM Gaussian (identidad)\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "glm_gauss = sm.GLM(y_train, X_train_sm, family=sm.families.Gaussian()).fit()\n",
    "y_pred_glm = glm_gauss.predict(X_test_sm)\n",
    "evaluate_model(\"GLM_Gaussian\", y_test, y_pred_glm, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe25cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Ridge Regression\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "evaluate_model(\"Ridge\", y_test, y_pred_ridge, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a86f5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£ Lasso Regression\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "evaluate_model(\"Lasso\", y_test, y_pred_lasso, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a651e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5Ô∏è‚É£ Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "evaluate_model(\"RandomForest\", y_test, y_pred_rf, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76082ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6Ô∏è‚É£ XGBoost Regressor\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "evaluate_model(\"XGBoost\", y_test, y_pred_xgb, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12c254b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7Ô∏è‚É£ Beta Regression (requires scaling y between (0,1))\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Convert Series to NumPy arrays and reshape before scaling\n",
    "y_train_beta = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_beta = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Fit the Beta Regression model\n",
    "glm_beta = GLM(y_train_beta, X_train_sm, family=sm.families.Binomial(link=sm.families.links.logit()))\n",
    "beta_model = glm_beta.fit()\n",
    "\n",
    "# Make predictions\n",
    "y_pred_beta = beta_model.predict(X_test_sm)\n",
    "\n",
    "# Reverse scaling to get predictions in the original scale\n",
    "y_pred_beta_rescaled = scaler_y.inverse_transform(y_pred_beta.to_numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(\"BetaRegression_scaled\", y_test, y_pred_beta_rescaled, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f04da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CatBoost Regressor\n",
    "catboost = CatBoostRegressor(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    verbose=0,\n",
    "    random_seed=42\n",
    ")\n",
    "catboost.fit(X_train, y_train)\n",
    "y_pred_catboost = catboost.predict(X_test)\n",
    "evaluate_model(\"CatBoost\", y_test, y_pred_catboost, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f88b1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2358\n",
      "[LightGBM] [Info] Number of data points in the train set: 625, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.378979\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgbm = LGBMRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_pred_lgbm = lgbm.predict(X_test)\n",
    "evaluate_model(\"LightGBM\", y_test, y_pred_lgbm, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73d46159",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb = HistGradientBoostingRegressor(\n",
    "    max_iter=100,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "hgb.fit(X_train, y_train)\n",
    "y_pred_hgb = hgb.predict(X_test)\n",
    "evaluate_model(\"HistGradientBoosting\", y_test, y_pred_hgb, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4407a1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Model Comparison:\n",
      "                           RMSE        R2\n",
      "CatBoost               0.407501  0.863128\n",
      "RandomForest           0.411677  0.860308\n",
      "XGBoost                0.422940  0.852560\n",
      "HistGradientBoosting   0.433288  0.845257\n",
      "LightGBM               0.434757  0.844206\n",
      "Ridge                  0.474136  0.814705\n",
      "GLM_Gaussian           0.477822  0.811812\n",
      "LinearRegression       0.477822  0.811812\n",
      "BetaRegression_scaled  0.485072  0.806058\n",
      "Lasso                  0.684785  0.613484\n"
     ]
    }
   ],
   "source": [
    "# üìã Mostrar resultados\n",
    "results_df = pd.DataFrame(results).T.sort_values(by=\"RMSE\")\n",
    "print(\"üìä Model Comparison:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d98c4ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Cross-Validation Results:\n",
      "                  CV RMSE (mean)  CV RMSE (std)\n",
      "RandomForest            0.417884       0.022192\n",
      "XGBoost                 0.424532       0.021658\n",
      "Ridge                   0.510341       0.028423\n",
      "LinearRegression        0.510508       0.028562\n",
      "Lasso                   0.558920       0.034985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# üîÅ Definir la validaci√≥n cruzada (por ejemplo, KFold con 5 particiones)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# üì¶ Modelos a evaluar (excepto GLM y Beta)\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.1),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "# üìä Evaluaci√≥n de cada modelo con cross-validation\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Pipeline para escalar y ajustar (excepto Random Forest/XGBoost, pero no afecta negativamente)\n",
    "    pipeline = make_pipeline(StandardScaler(), model)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring='neg_root_mean_squared_error')  # Neg RMSE\n",
    "    cv_results[name] = {\n",
    "        \"CV RMSE (mean)\": -np.mean(scores),\n",
    "        \"CV RMSE (std)\": np.std(scores)\n",
    "    }\n",
    "\n",
    "# üìã Mostrar resultados\n",
    "cv_df = pd.DataFrame(cv_results).T.sort_values(by=\"CV RMSE (mean)\")\n",
    "print(\"üîÅ Cross-Validation Results:\")\n",
    "print(cv_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c93dd129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en formato Pickle\n",
    "with open(\"../models/catboost_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(catboost, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
