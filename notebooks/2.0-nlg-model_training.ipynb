{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab6a22e",
   "metadata": {},
   "source": [
    "# **Happiness Score Prediction -  Machine Learning**\n",
    "\n",
    "-------------------------------------------------------\n",
    "\n",
    "##  **Objective**\n",
    "Train a **regression machine learning model** to predict the **happiness score** using **a  CSV files**  on world happiness data from 2015 to 2019.The workflow includes:\n",
    "\n",
    "- **Extracting features** from raw datasets (ETL process).\n",
    "- **Training a regression model** using a **70-30 data split** (70% training, 30% testing).\n",
    "- **Streaming transformed data** to a consumer.\n",
    "- **Using the trained model** in the consumer to predict happiness scores.\n",
    "- **Storing predictions** with the corresponding features in a database.\n",
    "- **Evaluating performance** using **testing data and predicted values**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Workflow Overview**\n",
    "\n",
    "**Feature Engineering**  \n",
    "   - Normalize `happiness_score` to fit within **[0,10]**.  \n",
    "   - Scale numerical features using **MinMaxScaler** or **StandardScaler**.  \n",
    "\n",
    "**Model Training**  \n",
    "   - Use a **70-30 train-test split** to train the model.  \n",
    "   - Compare different regression models:\n",
    "     - **Linear Regression**\n",
    "     - **Ridge & Lasso Regression**\n",
    "     - **Random Forest Regressor**\n",
    "     - **XGBoost Regressor**\n",
    "   - **Tune hyperparameters** to improve performance.\n",
    "\n",
    " **Data Streaming**  \n",
    "   - Stream **transformed data** to a consumer.\n",
    "   - Retrieve data from the consumer.\n",
    "   - Use the **trained model** to make predictions.\n",
    "\n",
    " **Database Storage**  \n",
    "   - Store **predictions along with input features** in a database.  \n",
    "   - Ensure data **integrity and accessibility** for future analysis.\n",
    "\n",
    "**Model Evaluation**  \n",
    "   - Compute **Mean Squared Error (MSE)** and **R²**.  \n",
    "   - Analyze **residual distributions** for normality.  \n",
    "   - Validate against **real-world happiness scores**.\n",
    "\n",
    "\n",
    "## **Metadata**\n",
    "- **Author:** Natalia López Gallego  \n",
    "- **Python Version:** 3.12.10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d28d72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model selection y preprocesamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Modelos de regresión\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "# Métricas de evaluación\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "# Statsmodels para modelos estadísticos\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.othermod.betareg as betareg\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ff6293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health_x_economy</th>\n",
       "      <th>freedom</th>\n",
       "      <th>family</th>\n",
       "      <th>health</th>\n",
       "      <th>economy_t-1_x_health_t-1</th>\n",
       "      <th>family_generosity_ratio</th>\n",
       "      <th>continent</th>\n",
       "      <th>happiness_score</th>\n",
       "      <th>trust</th>\n",
       "      <th>economy_health_ratio</th>\n",
       "      <th>health_x_country_economy_mean</th>\n",
       "      <th>economy</th>\n",
       "      <th>family_t-1_x_freedom_t-1</th>\n",
       "      <th>country_economy_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097017</td>\n",
       "      <td>0.23414</td>\n",
       "      <td>1.029510</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.819726</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.575</td>\n",
       "      <td>0.097190</td>\n",
       "      <td>1.054259</td>\n",
       "      <td>0.108330</td>\n",
       "      <td>0.319820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066301</td>\n",
       "      <td>0.16430</td>\n",
       "      <td>0.110370</td>\n",
       "      <td>0.173440</td>\n",
       "      <td>0.097017</td>\n",
       "      <td>0.352969</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.360</td>\n",
       "      <td>0.071120</td>\n",
       "      <td>2.203920</td>\n",
       "      <td>0.061938</td>\n",
       "      <td>0.382270</td>\n",
       "      <td>0.241049</td>\n",
       "      <td>0.357113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072566</td>\n",
       "      <td>0.10618</td>\n",
       "      <td>0.581543</td>\n",
       "      <td>0.180747</td>\n",
       "      <td>0.066301</td>\n",
       "      <td>1.864633</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.794</td>\n",
       "      <td>0.061158</td>\n",
       "      <td>2.221091</td>\n",
       "      <td>0.064547</td>\n",
       "      <td>0.401477</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>0.357113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.084660</td>\n",
       "      <td>0.08500</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.072566</td>\n",
       "      <td>2.811371</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.632</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>1.301910</td>\n",
       "      <td>0.091064</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.357113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.126350</td>\n",
       "      <td>0.41700</td>\n",
       "      <td>0.517000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.084660</td>\n",
       "      <td>3.271945</td>\n",
       "      <td>Asia</td>\n",
       "      <td>3.203</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.969502</td>\n",
       "      <td>0.128918</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.045645</td>\n",
       "      <td>0.357113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   health_x_economy  freedom    family    health  economy_t-1_x_health_t-1  \\\n",
       "0          0.097017  0.23414  1.029510  0.303350                  0.000000   \n",
       "1          0.066301  0.16430  0.110370  0.173440                  0.097017   \n",
       "2          0.072566  0.10618  0.581543  0.180747                  0.066301   \n",
       "3          0.084660  0.08500  0.537000  0.255000                  0.072566   \n",
       "4          0.126350  0.41700  0.517000  0.361000                  0.084660   \n",
       "\n",
       "   family_generosity_ratio continent  happiness_score     trust  \\\n",
       "0                 2.819726      Asia            3.575  0.097190   \n",
       "1                 0.352969      Asia            3.360  0.071120   \n",
       "2                 1.864633      Asia            3.794  0.061158   \n",
       "3                 2.811371      Asia            3.632  0.036000   \n",
       "4                 3.271945      Asia            3.203  0.025000   \n",
       "\n",
       "   economy_health_ratio  health_x_country_economy_mean   economy  \\\n",
       "0              1.054259                       0.108330  0.319820   \n",
       "1              2.203920                       0.061938  0.382270   \n",
       "2              2.221091                       0.064547  0.401477   \n",
       "3              1.301910                       0.091064  0.332000   \n",
       "4              0.969502                       0.128918  0.350000   \n",
       "\n",
       "   family_t-1_x_freedom_t-1  country_economy_mean  \n",
       "0                  0.000000              0.357113  \n",
       "1                  0.241049              0.357113  \n",
       "2                  0.018134              0.357113  \n",
       "3                  0.061748              0.357113  \n",
       "4                  0.045645              0.357113  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/interim/happiness_data_alternative.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3033d115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   health_x_economy  freedom    family    health  economy_t-1_x_health_t-1  \\\n",
      "0          0.097017  0.23414  1.029510  0.303350                  0.000000   \n",
      "1          0.066301  0.16430  0.110370  0.173440                  0.097017   \n",
      "2          0.072566  0.10618  0.581543  0.180747                  0.066301   \n",
      "3          0.084660  0.08500  0.537000  0.255000                  0.072566   \n",
      "4          0.126350  0.41700  0.517000  0.361000                  0.084660   \n",
      "\n",
      "   family_generosity_ratio  happiness_score     trust  economy_health_ratio  \\\n",
      "0                 2.819726            3.575  0.097190              1.054259   \n",
      "1                 0.352969            3.360  0.071120              2.203920   \n",
      "2                 1.864633            3.794  0.061158              2.221091   \n",
      "3                 2.811371            3.632  0.036000              1.301910   \n",
      "4                 3.271945            3.203  0.025000              0.969502   \n",
      "\n",
      "   health_x_country_economy_mean   economy  family_t-1_x_freedom_t-1  \\\n",
      "0                       0.108330  0.319820                  0.000000   \n",
      "1                       0.061938  0.382270                  0.241049   \n",
      "2                       0.064547  0.401477                  0.018134   \n",
      "3                       0.091064  0.332000                  0.061748   \n",
      "4                       0.128918  0.350000                  0.045645   \n",
      "\n",
      "   country_economy_mean  continent_Asia  continent_Europe  \\\n",
      "0              0.357113             1.0               0.0   \n",
      "1              0.357113             1.0               0.0   \n",
      "2              0.357113             1.0               0.0   \n",
      "3              0.357113             1.0               0.0   \n",
      "4              0.357113             1.0               0.0   \n",
      "\n",
      "   continent_North America  continent_Oceania  continent_South America  \\\n",
      "0                      0.0                0.0                      0.0   \n",
      "1                      0.0                0.0                      0.0   \n",
      "2                      0.0                0.0                      0.0   \n",
      "3                      0.0                0.0                      0.0   \n",
      "4                      0.0                0.0                      0.0   \n",
      "\n",
      "   continent_Unknown  \n",
      "0                0.0  \n",
      "1                0.0  \n",
      "2                0.0  \n",
      "3                0.0  \n",
      "4                0.0  \n"
     ]
    }
   ],
   "source": [
    "# Use 'sparse_output=False' instead of 'sparse=False'\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "encoded_continent = encoder.fit_transform(df[[\"continent\"]])\n",
    "\n",
    "# Convert the encoded array to a DataFrame\n",
    "import pandas as pd\n",
    "continent_df = pd.DataFrame(encoded_continent, columns=encoder.get_feature_names_out([\"continent\"]))\n",
    "\n",
    "# Drop the original 'continent' column and join the new one-hot encoded columns\n",
    "df = df.drop(columns=[\"continent\"]).join(continent_df)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e08b3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    'economy_t-1_x_health_t-1': 'economy_t1_x_health_t1',\n",
    "    'family_t-1_x_freedom_t-1': 'family_t1_x_freedom_t1'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e951505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable and feature definition\n",
    "\n",
    "X = df.drop(columns=[\"happiness_score\"])\n",
    "y = df[\"happiness_score\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0363d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb34071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name: str, y_true: np.ndarray, y_pred: np.ndarray, results: dict) -> None:\n",
    "    \"\"\"\n",
    "    Evaluates a regression model's performance and stores the results.\n",
    "\n",
    "    Parameters:\n",
    "    - name (str): The name of the model.\n",
    "    - y_true (np.ndarray): Array of actual target values.\n",
    "    - y_pred (np.ndarray): Array of predicted target values.\n",
    "    - results (dict): Dictionary to store evaluation metrics.\n",
    "\n",
    "    Returns:\n",
    "    - None: The function updates the results dictionary in-place.\n",
    "    \"\"\"\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)  # Updated function\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    results[name] = {'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "#  Dictionary to store results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d46df20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "evaluate_model(\"LinearRegression\", y_test, y_pred_lr, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25f48a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2️⃣ GLM Gaussian (identidad)\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "glm_gauss = sm.GLM(y_train, X_train_sm, family=sm.families.Gaussian()).fit()\n",
    "y_pred_glm = glm_gauss.predict(X_test_sm)\n",
    "evaluate_model(\"GLM_Gaussian\", y_test, y_pred_glm, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe25cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3️⃣ Ridge Regression\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "evaluate_model(\"Ridge\", y_test, y_pred_ridge, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a86f5afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ntlg2\\Documents\\etl-workshop-3\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.587e-01, tolerance: 8.023e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# 4️⃣ Lasso Regression\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "evaluate_model(\"Lasso\", y_test, y_pred_lasso, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a651e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5️⃣ Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "evaluate_model(\"RandomForest\", y_test, y_pred_rf, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76082ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6️⃣ XGBoost Regressor\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "evaluate_model(\"XGBoost\", y_test, y_pred_xgb, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c254b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ntlg2\\Documents\\etl-workshop-3\\venv\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:13: FutureWarning: The logit link alias is deprecated. Use Logit instead. The logit link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 7️⃣ Beta Regression (requires scaling y between (0,1))\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Convert Series to NumPy arrays and reshape before scaling\n",
    "y_train_beta = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_beta = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Fit the Beta Regression model\n",
    "glm_beta = GLM(y_train_beta, X_train_sm, family=sm.families.Binomial(link=sm.families.links.logit()))\n",
    "beta_model = glm_beta.fit()\n",
    "\n",
    "# Make predictions\n",
    "y_pred_beta = beta_model.predict(X_test_sm)\n",
    "\n",
    "# Reverse scaling to get predictions in the original scale\n",
    "y_pred_beta_rescaled = scaler_y.inverse_transform(y_pred_beta.to_numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(\"BetaRegression_scaled\", y_test, y_pred_beta_rescaled, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f04da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CatBoost Regressor\n",
    "catboost = CatBoostRegressor(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    verbose=0,\n",
    "    random_seed=42\n",
    ")\n",
    "catboost.fit(X_train, y_train)\n",
    "y_pred_catboost = catboost.predict(X_test)\n",
    "evaluate_model(\"CatBoost\", y_test, y_pred_catboost, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f88b1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2358\n",
      "[LightGBM] [Info] Number of data points in the train set: 625, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 5.378979\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgbm = LGBMRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_pred_lgbm = lgbm.predict(X_test)\n",
    "evaluate_model(\"LightGBM\", y_test, y_pred_lgbm, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73d46159",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb = HistGradientBoostingRegressor(\n",
    "    max_iter=100,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "hgb.fit(X_train, y_train)\n",
    "y_pred_hgb = hgb.predict(X_test)\n",
    "evaluate_model(\"HistGradientBoosting\", y_test, y_pred_hgb, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4407a1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Model Comparison:\n",
      "                           RMSE        R2\n",
      "CatBoost               0.407501  0.863128\n",
      "RandomForest           0.411677  0.860308\n",
      "XGBoost                0.422940  0.852560\n",
      "HistGradientBoosting   0.433288  0.845257\n",
      "LightGBM               0.434757  0.844206\n",
      "Ridge                  0.474136  0.814705\n",
      "GLM_Gaussian           0.477822  0.811812\n",
      "LinearRegression       0.477822  0.811812\n",
      "BetaRegression_scaled  0.485072  0.806058\n",
      "Lasso                  0.684785  0.613484\n"
     ]
    }
   ],
   "source": [
    "# 📋 Mostrar resultados\n",
    "results_df = pd.DataFrame(results).T.sort_values(by=\"RMSE\")\n",
    "print(\"📊 Model Comparison:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d98c4ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Cross-Validation Results:\n",
      "                  CV RMSE (mean)  CV RMSE (std)\n",
      "RandomForest            0.417884       0.022192\n",
      "XGBoost                 0.424532       0.021658\n",
      "Ridge                   0.510341       0.028423\n",
      "LinearRegression        0.510508       0.028562\n",
      "Lasso                   0.558920       0.034985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 🔁 Definir la validación cruzada (por ejemplo, KFold con 5 particiones)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 📦 Modelos a evaluar (excepto GLM y Beta)\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.1),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "# 📊 Evaluación de cada modelo con cross-validation\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Pipeline para escalar y ajustar (excepto Random Forest/XGBoost, pero no afecta negativamente)\n",
    "    pipeline = make_pipeline(StandardScaler(), model)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring='neg_root_mean_squared_error')  # Neg RMSE\n",
    "    cv_results[name] = {\n",
    "        \"CV RMSE (mean)\": -np.mean(scores),\n",
    "        \"CV RMSE (std)\": np.std(scores)\n",
    "    }\n",
    "\n",
    "# 📋 Mostrar resultados\n",
    "cv_df = pd.DataFrame(cv_results).T.sort_values(by=\"CV RMSE (mean)\")\n",
    "print(\"🔁 Cross-Validation Results:\")\n",
    "print(cv_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c93dd129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en formato Pickle\n",
    "with open(\"../models/catboost_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(catboost, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
